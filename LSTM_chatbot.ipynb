{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NSDflwTHL7Bh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalAveragePooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7a8UUQ4YMFSI"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file into a Python object\n",
        "with open('content.json') as content:\n",
        "    data1 = json.load(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0iJdBY1cMFVT"
      },
      "outputs": [],
      "source": [
        "#getting all data to lists\n",
        "inputs = []\n",
        "tags = []\n",
        "responses={}\n",
        "# Iterate through each intent and add its inputs and tags to the lists\n",
        "for intent in data1['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['input']:\n",
        "        inputs.append(lines)\n",
        "        tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhwwKJ9IMFad"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame from the lists of inputs and tags\n",
        "data = pd.DataFrame({'inputs': inputs, \n",
        "                   'tags': tags})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M1Y6eENMFdV"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8XwZ0EXPZsT"
      },
      "outputs": [],
      "source": [
        "#Preprocessing\n",
        "#Remove punctuation from the input text\n",
        "import string\n",
        "data['inputs'] = data['inputs'].apply(lambda word:[letter.lower() for letter in word if letter not in string.punctuation])\n",
        "data['inputs'] = data['inputs'].apply(lambda word: ''.join(word))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcdWh8dGPZvc"
      },
      "outputs": [],
      "source": [
        "#tokenize the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(df['inputs'])\n",
        "train = tokenizer.texts_to_sequences(df['inputs'])\n",
        "\n",
        "#apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "#encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(df['tags'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iok1uLzSwjb"
      },
      "outputs": [],
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKuqMXayS6-t"
      },
      "outputs": [],
      "source": [
        "# Define vocabulary\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"Number of unique words: \", vocabulary)\n",
        "\n",
        "output_length = le.classes_.shape[0]\n",
        "print(\"Output length: \", output_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0A0LMBKS7H1"
      },
      "outputs": [],
      "source": [
        "# Define the model \n",
        "i = Input(shape=input_shape)\n",
        "x = Embedding(vocabulary+1, 10)(i)\n",
        "x = LSTM(10, return_sequences=True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model(inputs=i, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnzGc6NKUNmd"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuOLiaiwUNr8"
      },
      "outputs": [],
      "source": [
        "#train the model\n",
        "train = model.fit(x_train, y_train, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUGweUcfUiER"
      },
      "outputs": [],
      "source": [
        "plt.plot(train.history['accuracy'], label='Training set accuracy')\n",
        "plt.plot(train.history['loss'], label='Training set loss')\n",
        "plt.title('Training accuracy and loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy/Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htjo9wiLUiHi"
      },
      "outputs": [],
      "source": [
        "#Testing\n",
        "import random\n",
        "import string\n",
        "while True:\n",
        "    texts_p = []\n",
        "    prediction_input = input('You: ')\n",
        "\n",
        "    # Removing punctuation and converting to lowercase\n",
        "    prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "    prediction_input =''.join(prediction_input)\n",
        "    texts_p.append(prediction_input)\n",
        "\n",
        "    # Tokenizing and padding prediction_input\n",
        "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "    prediction_input = np.array(prediction_input).reshape(-1)\n",
        "    prediction_input = pad_sequences([prediction_input], input_shape)\n",
        "\n",
        "    # Getting output from model\n",
        "    output = model.predict(prediction_input)\n",
        "    output = output.argmax()\n",
        "\n",
        "    # Finding the right tag and predicting response\n",
        "    response_tag = le.inverse_transform([output])[0]\n",
        "    print(\"Going Merry: \",random.choice(responses[response_tag]))\n",
        "    if response_tag == \"goodbye\":\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xDWG4etUwu5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0lHdF6VUwxN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS4oxApPUwzi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}